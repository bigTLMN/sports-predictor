import optuna
import xgboost as xgb
import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, mean_absolute_error
from train_model import load_and_clean_data, prepare_training_data, TRAIN_FEATURES_SPREAD, TRAIN_FEATURES_TOTAL

# è®€å–ä¸€æ¬¡è³‡æ–™å³å¯ï¼Œä¸ç”¨é‡è¤‡è®€å–
print("ğŸ“‚ è®€å–è³‡æ–™ä¸­...")
df = load_and_clean_data()
data = prepare_training_data(df)

# åˆ‡åˆ†è³‡æ–™ (èˆ‡ train_model.py ä¿æŒä¸€è‡´ï¼Œ85% è¨“ç·´ / 15% é©—è­‰)
split_idx = int(len(data) * 0.85)
train_data = data.iloc[:split_idx]
test_data = data.iloc[split_idx:]

print(f"ğŸ“Š è¨“ç·´é›†: {len(train_data)}, é©—è­‰é›†: {len(test_data)}")

# ==========================================
# 1. èª¿å„ªç›®æ¨™ï¼šå‹è² é æ¸¬ (Maximize Accuracy)
# ==========================================
def objective_win(trial):
    # å®šç¾©åƒæ•¸æœå°‹ç©ºé–“
    param = {
        'eval_metric': 'logloss',
        'use_label_encoder': False,
        'booster': 'gbtree',
        # é—œéµåƒæ•¸
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
        'gamma': trial.suggest_float('gamma', 0, 5),
        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),
        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),
        'missing': np.nan
    }

    model = xgb.XGBClassifier(**param)
    
    # è¨“ç·´
    model.fit(train_data[TRAIN_FEATURES_SPREAD], train_data['target_win'])
    
    # é æ¸¬
    preds = model.predict(test_data[TRAIN_FEATURES_SPREAD])
    accuracy = accuracy_score(test_data['target_win'], preds)
    
    return accuracy

# ==========================================
# 2. èª¿å„ªç›®æ¨™ï¼šè®“åˆ†/å¤§å° (Minimize MAE)
# ==========================================
def objective_reg(trial, target_col, features):
    param = {
        'objective': 'reg:squarederror',
        'booster': 'gbtree',
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),
        'subsample': trial.suggest_float('subsample', 0.5, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
        'gamma': trial.suggest_float('gamma', 0, 5),
        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),
        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),
        'missing': np.nan
    }
    
    model = xgb.XGBRegressor(**param)
    model.fit(train_data[features], train_data[target_col])
    
    preds = model.predict(test_data[features])
    mae = mean_absolute_error(test_data[target_col], preds)
    
    return mae

if __name__ == "__main__":
    print("\nğŸ” é–‹å§‹å°‹æ‰¾ [å‹è² é æ¸¬] çš„é»ƒé‡‘åƒæ•¸...")
    study_win = optuna.create_study(direction='maximize')
    study_win.optimize(objective_win, n_trials=50) # è©¦è·‘ 50 æ¬¡ï¼Œæƒ³æ›´æº–å¯ä»¥æ”¹ 100
    
    print("\nğŸ” é–‹å§‹å°‹æ‰¾ [è®“åˆ†é æ¸¬] çš„é»ƒé‡‘åƒæ•¸...")
    study_spread = optuna.create_study(direction='minimize')
    study_spread.optimize(lambda trial: objective_reg(trial, 'target_margin', TRAIN_FEATURES_SPREAD), n_trials=50)

    print("\nğŸ” é–‹å§‹å°‹æ‰¾ [å¤§å°åˆ†é æ¸¬] çš„é»ƒé‡‘åƒæ•¸...")
    study_total = optuna.create_study(direction='minimize')
    study_total.optimize(lambda trial: objective_reg(trial, 'target_total', TRAIN_FEATURES_TOTAL), n_trials=50)
    
    print("\n" + "="*50)
    print("ğŸ† èª¿å„ªçµæœå ±å‘Š (è«‹å°‡é€™äº›åƒæ•¸å¡«å› train_model.py)")
    print("="*50)
    
    print("\nğŸ¤– [Win Model] Best Accuracy:", study_win.best_value)
    print("Best Params:", study_win.best_params)
    
    print("\nğŸ¤– [Spread Model] Best MAE:", study_spread.best_value)
    print("Best Params:", study_spread.best_params)
    
    print("\nğŸ¤– [Total Model] Best MAE:", study_total.best_value)
    print("Best Params:", study_total.best_params)