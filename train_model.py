import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_absolute_error
import joblib
import os

# ==========================================
# 1. å®šç¾©ç‰¹å¾µæ¬„ä½
# ==========================================
RAW_FEATURES = [
    'fieldGoalsPercentage', 'threePointersPercentage', 'freeThrowsPercentage',
    'reboundsTotal', 'assists', 'steals', 'blocks', 'turnovers', 
    'plusMinusPoints', 'pointsInThePaint', 'teamScore' # ä¿ç•™ teamScore ç”¨ä¾†ç®— Targetï¼Œä½†ä¸æ”¾å…¥è¨“ç·´ç‰¹å¾µ
]

# è¨“ç·´ç”¨çš„ç‰¹å¾µ (å·²ç§»é™¤ teamScoreï¼Œé˜²æ­¢ Data Leakage)
TRAIN_FEATURES_SPREAD = [
    'is_home', 
    'diff_fieldGoalsPercentage', 'diff_threePointersPercentage', 'diff_freeThrowsPercentage',
    'diff_reboundsTotal', 'diff_assists', 'diff_steals', 'diff_blocks', 'diff_turnovers',
    'diff_plusMinusPoints', 'diff_pointsInThePaint'
]

TRAIN_FEATURES_TOTAL = [
    'sum_fieldGoalsPercentage', 'sum_threePointersPercentage', 'sum_freeThrowsPercentage',
    'sum_reboundsTotal', 'sum_assists', 'sum_steals', 'sum_blocks', 'sum_turnovers',
    'sum_plusMinusPoints', 'sum_pointsInThePaint'
]

def load_and_clean_data():
    print("ğŸ“‚ [V3] æ­£åœ¨è®€å– TeamStatistics.csv ...")
    try:
        # åªè®€å–éœ€è¦çš„æ¬„ä½
        cols = ['gameId', 'teamId', 'gameDateTimeEst', 'home', 'win', 'teamScore', 'opponentScore'] + RAW_FEATURES
        df = pd.read_csv('data/TeamStatistics.csv', usecols=cols, low_memory=False)

        # ğŸ”¥ é—œéµä¿®å¾©ï¼šå¼·åˆ¶æ­£è¦åŒ–æ—¥æœŸ (åªå–å‰ 10 ç¢¼ YYYY-MM-DD)
        # é€™èƒ½è§£æ±ºå¸¶æœ‰æ™‚å€ (-04:00) æˆ–é‡è¤‡ Header å°è‡´è§£æå¤±æ•—çš„å•é¡Œ
        df['gameDateTimeEst'] = df['gameDateTimeEst'].astype(str).str.slice(0, 10)
        
        # ä½¿ç”¨ errors='coerce' è‡ªå‹•éæ¿¾ç„¡æ³•è§£æçš„æ—¥æœŸ
        df['gameDateTimeEst'] = pd.to_datetime(df['gameDateTimeEst'], utc=True, errors='coerce')
        
        # ç§»é™¤ç„¡æ•ˆæ—¥æœŸ
        df = df.dropna(subset=['gameDateTimeEst'])
        
        if df.empty:
            print("âŒ éŒ¯èª¤ï¼šDataFrame ç‚ºç©ºï¼è«‹æª¢æŸ¥ CSV æ—¥æœŸæ ¼å¼ã€‚")
            exit()

        # æ’åº
        df = df.sort_values(['teamId', 'gameDateTimeEst'])
        
        # æ»¾å‹•å¹³å‡ (Rolling Average) - è¨ˆç®—è¿‘ 5 å ´è¡¨ç¾
        # ä½¿ç”¨ group_keys=False ä¿æŒç´¢å¼•æ•´æ½”
        df_rolled = df.groupby('teamId', group_keys=False)[RAW_FEATURES].apply(lambda x: x.shift(1).rolling(5, min_periods=1).mean())
        
        # æŠŠåŸå§‹è³‡è¨Šæ¥å›ä¾†
        for col in ['gameId', 'gameDateTimeEst', 'home', 'win', 'teamScore', 'opponentScore']:
            df_rolled[col] = df[col]
            
        # ç§»é™¤å‰å¹¾å ´æ²’æœ‰æ»¾å‹•æ•¸æ“šçš„è¡Œ
        df_rolled = df_rolled.dropna()
        
        return df_rolled

    except Exception as e:
        print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        exit()

def prepare_training_data(df):
    print("ğŸ”„ [V3] ç‰¹å¾µå·¥ç¨‹ï¼šè¨ˆç®— Diff (è®“åˆ†ç”¨) èˆ‡ Sum (å¤§å°åˆ†ç”¨)...")
    
    df_home = df[df['home'] == 1].copy()
    df_away = df[df['home'] == 0].copy()
    
    merged = pd.merge(df_home, df_away, on='gameId', suffixes=('_h', '_a'))
    
    merged['is_home'] = 1 
    
    for col in RAW_FEATURES:
        merged[f'diff_{col}'] = merged[f'{col}_h'] - merged[f'{col}_a']
        merged[f'sum_{col}'] = merged[f'{col}_h'] + merged[f'{col}_a']
        
    merged['target_win'] = merged['win_h'] 
    merged['target_margin'] = merged['teamScore_h'] - merged['teamScore_a']
    merged['target_total'] = merged['teamScore_h'] + merged['teamScore_a']
    
    return merged

def train():
    df = load_and_clean_data()
    
    if len(df) < 10:
        print(f"âŒ è³‡æ–™é‡éå°‘ ({len(df)} ç­†)ï¼Œç„¡æ³•è¨“ç·´ã€‚")
        exit()

    data = prepare_training_data(df)
    
    # --- æ¨¡å‹ 1: å‹è² é æ¸¬ ---
    print("\nğŸ¤– è¨“ç·´æ¨¡å‹ 1: å‹è² é æ¸¬ (Win/Loss)...")
    X_win = data[TRAIN_FEATURES_SPREAD]
    y_win = data['target_win']
    
    X_train, X_test, y_train, y_test = train_test_split(X_win, y_win, test_size=0.2, random_state=42)
    # ğŸ”¥ ä¿®æ­£ï¼šç§»é™¤äº† use_label_encoder=False
    model_win = xgb.XGBClassifier(eval_metric='logloss')
    model_win.fit(X_train, y_train)
    
    preds = model_win.predict(X_test)
    acc = accuracy_score(y_test, preds)
    print(f"   ğŸ¯ å‹ç‡æº–ç¢ºåº¦: {acc*100:.2f}%")
    
    # --- æ¨¡å‹ 2: è®“åˆ†é æ¸¬ ---
    print("\nğŸ¤– è¨“ç·´æ¨¡å‹ 2: è®“åˆ†é æ¸¬ (Spread Margin)...")
    X_spread = data[TRAIN_FEATURES_SPREAD]
    y_spread = data['target_margin']
    
    X_train, X_test, y_train, y_test = train_test_split(X_spread, y_spread, test_size=0.2, random_state=42)
    model_spread = xgb.XGBRegressor(objective='reg:squarederror')
    model_spread.fit(X_train, y_train)
    
    preds = model_spread.predict(X_test)
    mae = mean_absolute_error(y_test, preds)
    print(f"   ğŸ“ å¹³å‡èª¤å·® (MAE): {mae:.2f} åˆ†")
    
    # --- æ¨¡å‹ 3: å¤§å°åˆ†é æ¸¬ ---
    print("\nğŸ¤– è¨“ç·´æ¨¡å‹ 3: å¤§å°åˆ†é æ¸¬ (Total Points)...")
    X_total = data[TRAIN_FEATURES_TOTAL]
    y_total = data['target_total']
    
    X_train, X_test, y_train, y_test = train_test_split(X_total, y_total, test_size=0.2, random_state=42)
    model_total = xgb.XGBRegressor(objective='reg:squarederror')
    model_total.fit(X_train, y_train)
    
    preds = model_total.predict(X_test)
    mae = mean_absolute_error(y_test, preds)
    print(f"   ğŸ“ å¹³å‡èª¤å·® (MAE): {mae:.2f} åˆ†")
    
    # --- å„²å­˜æ¨¡å‹ ---
    joblib.dump(model_win, 'model_win.pkl')
    joblib.dump(model_spread, 'model_spread.pkl')
    joblib.dump(model_total, 'model_total.pkl')
    joblib.dump(TRAIN_FEATURES_SPREAD, 'features_spread.pkl')
    joblib.dump(TRAIN_FEATURES_TOTAL, 'features_total.pkl')
    
    print("\nğŸ’¾ æ‰€æœ‰æ¨¡å‹èˆ‡ç‰¹å¾µå·²å„²å­˜å®Œç•¢ï¼")

if __name__ == "__main__":
    train()